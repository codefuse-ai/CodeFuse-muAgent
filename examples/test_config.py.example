import os, openai, base64
from loguru import logger

os.environ["DM_llm_name"] = 'Qwen2_72B_Instruct_OpsGPT'  #or  gpt_4

# 兜底大模型配置
OPENAI_API_BASE = "https://api.openai.com/v1"
os.environ["API_BASE_URL"] = OPENAI_API_BASE
os.environ["OPENAI_API_KEY"] = "sk-xxx"
openai.api_key = "sk-xxx"
os.environ["model_name"] = "gpt-3.5-turbo"
os.environ["model_engine"] = "openai"

# 涉及react模式时需要配置主持人的模型，起到起承转合的作用
# 推荐gpt-4
os.environ["gpt4-API_BASE_URL"] = OPENAI_API_BASE
os.environ["gpt4-OPENAI_API_KEY"] = ""
os.environ["gpt4-model_name"] = "gpt-4"
os.environ["gpt4-model_engine"] = "openai"
os.environ["gpt4-llm_temperature"] = "0.0"



MODEL_CONFIGS = {
    # old llm config
    "default": {
        "model_name": "gpt-3.5-turbo",
        "model_engine": "qwen",
        "temperature": "0", 
        "api_key": "",
        "api_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    },
    "codefuser":{
        "model_name": "gpt-4",
        "model_engine": "openai",
        "temperature": "0", 
        "api_key": "",
        "api_base_url": OPENAI_API_BASE,
    },
    # new llm config
    "dashscope_chat": {
        "model_type": "dashscope_chat",
        "model_name": "qwen2.5-72b-instruct" ,
        "api_key": "",
    },
    "moonshot_chat": {
        "model_type": "moonshot_chat",
        "model_name": "moonshot-v1-8k" ,
        "api_key": "",
    },
    "ollama_chat": {
        "model_type": "ollama_chat",
        "model_name": "qwen2.5-0.5b",
        "api_key": "",
    },
    "openai_chat": {
        "model_type": "openai_chat",
        "model_name": "gpt-4",
        "api_key": "",
    },
    "qwen_chat": {
        "model_type": "qwen_chat",
        "model_name": "qwen2.5-72b-instruct",
        "api_key": "",
    },
    "yi_chat": {
        "model_type": "yi_chat",
        "model_name": "yi-lightning" ,
        "api_key": "",
    },
    # embedding configs
    "dashscope_text_embedding": {
        "model_type": "dashscope_text_embedding",
        "model_name": "text-embedding-v3",
        "api_key": "",
    },
    "ollama_embedding": {
        "model_type": "ollama_embedding",
        "model_name": "qwen2.5-0.5b",
        "api_key": "",
    },
    "openai_embedding": {
        "model_type": "openai_embedding",
        "model_name": "text-embedding-ada-002",
        "api_key": "",
    },
    "qwen_text_embedding": {
        "model_type": "dashscope_text_embedding",
        "model_name": "text-embedding-v3",
        "api_key": "",
    },
}

os.environ["MODEL_CONFIGS"] = json.dumps(MODEL_CONFIGS)

####   NebulaHandler   ####
os.environ['nb_host'] = 'graphd'
os.environ['nb_port'] = '9669'
os.environ['nb_username'] = 'root'
os.environ['nb_password'] = 'nebula'
os.environ['nb_space'] = "client"

#### tbasehandler ####

## opensource-default###
os.environ['tb_host'] = 'redis-stack'
os.environ['tb_port'] = '6379'
os.environ['tb_username'] = ''
os.environ['tb_password'] = ''
os.environ['tb_definition_value'] = "opsgptkg"

# tbase-memory
os.environ["tb_type"] = "TbaseHandler"
os.environ["tb_index_name"] = "ekg_migration_new"
os.environ['tb_definition_value'] = 'message_test_new'
os.environ['tb_expire_time'] = '604800' #86400*7


#################
##  DB_CONFIGS ##
#################
DB_CONFIGS = {
    "gb_config": {
        "gb_type": "NebulaHandler",
        "extra_kwargs": {
            'host':'graphd',
            'port': '9669',
            'username': os.environ['nb_username'],
            'password': os.environ['nb_password'],
            'space': "client"
        }
    },
    "tb_config": {
        "tb_type": 'TBaseHandler',
        "index_name": "opsgptkg",
        "host": 'redis-stack',
        "port": '6379',
        "username": os.environ['tb_username'],
        "password": os.environ['tb_password'],
        "extra_kwargs": {
            "definition_value": "opsgptkg",
            "memory_definition_value": "opsgptkg_message"
        }
    }
}
os.environ["DB_CONFIGS"] = json.dumps(DB_CONFIGS)



########################################
########## 以下参数暂不涉及无需配置 ########
########################################
os.environ["embed_model"] = "{{embed_model_name}}"
os.environ["embed_model_path"] = "{{embed_model_path}}"

# 
os.environ["DUCKDUCKGO_PROXY"] = os.environ.get("DUCKDUCKGO_PROXY") or "socks5h://127.0.0.1:13659"

os.environ['operation_mode'] = 'open_source' # 'open_source' or 'antcode'
os.environ['config_path'] = ""


### call llm ###
os.environ['aes_encrypt_iv'] = ""

#gpt-4#
os.environ['gpt4_serviceName'] = ""
os.environ['gpt4_visitDomain'] = ""
os.environ['gpt4_visitBiz']    = ""
os.environ['gpt4_visitBizLine'] = ""
os.environ['gpt4_cacheInterval']     = ""
os.environ['gpt4_model']        = ""
os.environ['gpt4_api_key']      = ""

os.environ['gpt4_url']= ''
os.environ['gpt4_key']= ""

#modelops#
os.environ['modelops_url']= ""
os.environ['modelops_qwen_7b_chat_gpt_token'] =''
os.environ['modelops_qwen_7b_chat_gpt_Cookie']= ''

###意图识别###
os.environ['intention_url'] = ''


###old function###
OLD_PARAMS_STRING_EXAMPLE =  {}

os.environ['oldfunction_url'] = ''


### qa ###
os.environ['sre_agent_flow_url'] = ''